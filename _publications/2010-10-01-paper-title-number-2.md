---
title: "INFEATURE: An Interactive Feature-Based-Explanation Framework for Non-technical Users"
collection: publications
permalink: /publication/2010-10-01-paper-title-number-2
excerpt: 'This paper is about the number 2. The number 3 is left for future work.'
date: 2010-10-01
venue: 'International Conference on Human-Computer Interaction 2023'
paperurl: 'https://link.springer.com/chapter/10.1007/978-3-031-35891-3_16'
citation: 'Pi, Y. (2023). INFEATURE: An Interactive Feature-Based-Explanation Framework for Non-technical Users. In: Degen, H., Ntoa, S. (eds) Artificial Intelligence in HCI. HCII 2023. Lecture Notes in Computer Science(), vol 14050. Springer, Cham. https://doi.org/10.1007/978-3-031-35891-3_16'
---
Abstract: The field of explainable artificial intelligence (XAI) aims to make AI systems more understandable to humans. However, current XAI research often produces explanations that convey only one aspect of the information, ignoring the complementary nature of local and global explanations in the decision-making process. To address this issue, this study introduces an interactive interface based on feature-based explanations generated by SHAP. The interface presents feature-based explanations in an interactive and staggered manner, bridging the gap between local explanations and the overall understanding of the model. It allows users to explore datasets, models, and predictions in a self-discovery process that yields insights into model behavior in interaction with visual and verbal explanations. The interface also displays the confusion matrix in an intuitive way that takes the underlying data distributions into account.
